---
title: "Practica2"
author: "Jiaqian Lin"
date: "2021/01/01"
output: 
  pdf_document:
    number_sections: yes
    toc: yes
  word_document:
    toc: yes
toc-title: Índice
---
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage
# Detalles de la actividad

## Descripción
En esta actividad se elabora un caso práctico, consiste en el tratamiento de un conjunto de datos, orientad a aprender a identificar los datos relevante para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.  

## Objetivos
Los objetivos que se persiguen mediante el desarrollo de esta actividad práctica son los siguientes:  

* Aprender a aplicar los conocimientos adquiridos y su capacidad de resolución de problemas en entornos nuevos o poco conocidos dentro de contextos más amplios o multidisciplinares.  

* Saber identificar los datos relevantes y los tratamientos necesarios (integración, limpieza y validación) para llevar a cabo un proyecto analítico. 

* Aprender a analizar los datos adecuadamente para abordar la información contenida en los datos.  

* Identificar la mejor representación de los resultados para aportar conclusiones sobre el problema planteado en el proceso analítico.  

* Actuar con los principios éticos y legales relacionados con la manipulación de datos en función del ámbito de aplicación.  

* Desarrollar las habilidades de aprendizaje que les permitan continuar estudiando de un modo que tendrá que ser en gran medida autodirigido o autónomo.  

* Desarrollar la capacidad de búsqueda, gestión y uso de información y recursos en el ámbito de la ciencia de datos.    

## Competencias
En esta práctica se desarrollan las siguientes competencias del Master de Data Science:  

* Capacidad de analizar un problema en el nivel de abstracción adecuado a cada situación y aplicar las habilidades y conocimientos adquiridos para abordarlo y resolverlo.  

* Capacidad para aplicar las técnicas específicas de tratamiento de datos (integración, transformación, limpieza y validación) para su posterior análisis.  

\newpage
# Resolución

## Descripción

El conjunto de datos Titanic esta dividido en un subconjunto de entrenamiento y otro de test con 891 y 418 registros respectivamente. En el subconjunto de train tiene 12 variables:  

* PassengerId: variable numerico de tipo int que representa el Id de cada pasajero. 
* Survived: variable de salida que representa si el pasajero sobrevive o no. Es una variable categorica, donde 0 es negativo y 1 es positivo.  
* Pclass: variable categorico de tipo int que representa la clase de los pasarero. 1 es primera clase, 2 es segunda y 3 es tercera.  
* Name: variable de tipo string que determina el nombre de cada pasajero.  
* Sex: variable categorico de 2 niveles donde representa el sexo de los pasajeros.  
* Age: variable numerico de tipo int que representa la edad de cada pasajero.  
* Sibsp: variable numerico de tipo int que representa numero de hermanos / conyuges embarcados.  
* parch: variable numerico de tipo int que representa numero de padres / hijos embarcados.  
* ticket: variable de tipo string que determina el numero de ticket de cada pasajero.  
* Fare: variablen numerico de tipo double que representa el precio del ticket.  
* Cabin: variable de tipo string que representa el numero de la cabina.  
* Embarked: varianle categorico que representa el lugar de embarcamiento de los pasajeros. C-Cherbourg, Q-Queenstown y S-Southampton.  

En el subconjunto de test tiene las mismas variables menos la variable de salida survided.  

Nuestro objetivo es construir un modelo donde determinara si un pasajero sobrevive o no en el accidente de Titanic segun las variables de entrada. 

## Integración y selección de los datos de interés a analizar.
```{r}
# Importar dataset
train_df <- read.csv("./train.csv")
test_df <- read.csv("./test.csv")
head(train_df)
```

Para realizar esta practica, eliminaremos las variables Name, Ticket y Cabin ya que no son relevantes para el analisis posterior.
```{r}
train_df <- subset(train_df, select=-c(Ticket, Name, Cabin)) 
test_df <- subset(test_df, select=-c(Ticket, Name, Cabin))
```

## Limpieza de los datos.

### Valores nulos y en blanco
Encontrar valores nulos
```{r}
colSums(is.na(train_df))
colSums(is.na(test_df))
```

Encontramos 177 valores nulos en la variable age del subconjunto train y 86 valores nulos en el subconjunto test. Tambien encontramos un valor nulo en la variable Fare del subconjunto test. Para tratarlo, sustituiremos los valores nulos por la media de cada variable.  

```{r}
# imputación de la variable Age
train_df[is.na(train_df$Age),'Age'] <- round(mean(train_df$Age, na.rm = TRUE))
test_df[is.na(test_df$Age),'Age'] <- round(mean(test_df$Age, na.rm = TRUE))

# imputación de la variable fare
test_df[is.na(test_df$Fare),'Fare'] <- round(mean(test_df$Fare, na.rm = TRUE))
```

Una vez imputamos los valos nulos, buscaremos los valores vacios.
```{r}
colSums(train_df == '')
colSums(test_df == '')
```

Encontramos 2 casos de valores vacios en la variable Embarked del subconjunto train. Al ser una variable categorico, imputaremos estos valores mediante el metodo de knn.

```{r}
# convertir los dos valores vacios en NA para poder imputar despues
train_df$Embarked[train_df$Embarked == ''] <- NA

# Imputación de valores mediante la función kNN() del paquete VIM
suppressWarnings(suppressMessages(library(VIM)))
train_df$Embarked <- kNN(train_df)$Embarked
```

### Valores extremos
Los valores extremos o outliers son aquellos que parecen no ser congruentes sin los comparamos con el resto de los datos. No buscaremos valores extremos para la variable PassergerId ya que solo es un numero identificativo. Tampoco buscaremos valores extremos para las variables Survived, Pclass, Sex y Embarked porque son variables categoricos.
```{r}
# usar la funcion boxplot.stats() para encontrar los valores extremos
boxplot.stats(train_df$Age)$out
boxplot.stats(train_df$SibSp)$out
boxplot.stats(train_df$Parch)$out
boxplot.stats(train_df$Fare)$out

boxplot.stats(test_df$Age)$out
boxplot.stats(test_df$SibSp)$out
boxplot.stats(test_df$Parch)$out
boxplot.stats(test_df$Fare)$out
```

En cada variable se ha obtenido elevados numeros de valores extremos. Sin embargo, si revisamos los valores obtenidos, son valores que puede darse el caso aunque son valores atipicos (muy altos o muy bajos) y no son errores a la hora del registro.

## Analisis de los datos
Antes de comenzar a analizar, inspeccionaremos los datos.
```{r}
str(train_df)
str(test_df)
```

Observamos que las variables Survived y Pclass son numericos del tipo int en lugar de categorico que tenemos de convertirlos en factor y en la variable Embaked existe un nivel mas que tenemos que eliminar.
```{r}
# convertir en factor
train_df$Survived <- as.factor(train_df$Survived)
train_df$Pclass <- as.factor(train_df$Pclass)
test_df$Pclass <- as.factor(test_df$Pclass)

# eliminar el nivel "" de la variable Embarked
train_df$Embarked <- factor(train_df$Embarked)

# volver a mostrar la estructura de los dos subconjuntos
str(train_df)
str(test_df)
```

### Seleccion de los grupos de datos a analizar
Seleccionaremos los pasajeros por la clase, sexo y lugar de embarcamiento para analizar y comparar que efectos tiene estas variables sobre la supervivencia.
```{r}
# agrupacion por sexo
pasajeros.mujer <- train_df[train_df$Sex == 'female',]
pasajeros.hombre <- train_df[train_df$Sex == 'male',]

# agrupacion por clase
pasajeros.1ra <- train_df[train_df$Pclass == 1,]
pasajeros.2da <- train_df[train_df$Pclass == 2,]
pasajeros.3ra <- train_df[train_df$Pclass == 3,]

# agrupacion por lugar de embarcamiento  
pasajero.C <- train_df[train_df$Embarked == 'C',]
pasajero.Q <- train_df[train_df$Embarked == 'Q',]
pasajero.S <- train_df[train_df$Embarked == 'S',]

```

### Comprobación de la normalidad y homogeneidad de la varianza
Para la comprobación de que los valores que toman nuestras variables cuantitativas provienen de una población distribuida normalmente, utilizaremos la prueba de normalidad de Anderson-Darling.  
Así, se comprueba que para que cada prueba se obtiene un p-valor superior al nivel de significación prefijado alpha = 0, 05. Si esto se cumple, entonces se considera que variable en cuestión sigue una distribución normal.

```{r}
library(nortest)

alpha = 0.05
col.names = colnames(train_df)

for (i in 1:ncol(train_df)) {
  if (i == 1) cat("Variables que no siguen una distribución normal:\n")
  if (is.integer(train_df[,i]) | is.numeric(train_df[,i])) {
    p_val = ad.test(train_df[,i])$p.value
    if (p_val < alpha) {
      cat(col.names[i])
      
      # Format output
      if (i < ncol(train_df) - 1) cat(", ")
      if (i %% 3 == 0) cat("\n")
    }
  }
}
```

El resultado nos dice que ninguna de las variables continuas sigue una distribución normal. En el caso de PassegerId ya se podia decir ya que es simplemente una información para identificar los pasajeros.Comprobaremos la normalidad de las otras variables mediante metodos visuales.

```{r}
suppressWarnings(suppressMessages(library(ggpubr)))
suppressWarnings(suppressMessages(library("gridExtra")))
g1 <- ggqqplot(train_df$Age)
g2 <- ggqqplot(train_df$SibSp)
g3 <- ggqqplot(train_df$Parch)
g4 <- ggqqplot(train_df$Fare)
grid.arrange(g1,g2,g3,g4, nrow=2)

```

### Pruebas estadisticas
Vamos a hacer el test de chi-cuadrada entre la variable survived con otras variables para determinar cuales son mas importantes para nuestro modelo final de prediccion. Las variables que compararemos seran: Pclass, Sex y Embarked.
```{r}
chisq.test(train_df$Survived, train_df$Pclass)
chisq.test(train_df$Survived, train_df$Sex)
chisq.test(train_df$Survived, train_df$Embarked)

```

El valor p de los tres tests es inferior al 0.05, por lo cual quiere decir que estas tres variables son significantes y seran incluidos en el modelo final.

Tambien vamos a analizar las correlaciones entre las variables para saber que variables podemos dejar en la hora del modelado.
```{r}
library("corrplot")
res <- cor(train_df[,c(5,6,7,8)])
res

```

Podemos ver que no hay ninguna pareja de variable con una fuerte correlacion. Por lo tanto, incluiremos todas estas variables en el modelado final.

A continuacion miraremos como cuales son los grupos que es mas probable de sobrevivir.
```{r}
library(ggplot2)
# Visualizamos la relación entre las variables "sex" y "survived":
ggplot(data=train_df,aes(x=Sex,fill=Survived))+geom_bar()

# Otro punto de vista. Survived como función de Embarked:
ggplot(data = train_df,aes(x=Embarked,fill=Survived)) +
  geom_bar(position="fill")+ylab("Frecuencia")

# Y por lo ultimo, Survived como funcion de clase
ggplot(data=train_df,aes(x=Pclass,fill=Survived))+geom_bar()
```

Podemos ver que la proporción de mujeres que sobrevive es mucho mas alto que la proporcion de hombres. En la segunda grafica, observamos que los embarcados en Cherbourg es mas probable de sobrevivir que los embargados en Queenstown o Southamptom. Y en la ultima grafica observamos que los de la tercera clase solo sobrevive una pequeña proprción. Mientras los de la primera clase es mucho mas posible de sobrevivir.

```{r}
library(plyr)
# calcular numericamente las proporciones
sobrevive.mujer <- count(pasajeros.mujer, 
                         "Survived")$freq[2]/nrow(pasajeros.mujer)*100
sobrevive.hombre <- count(pasajeros.hombre, 
                         "Survived")$freq[2]/nrow(pasajeros.hombre)*100

sobrevive.C <- count(pasajero.C, 
                     "Survived")$freq[2]/nrow(pasajero.C)*100
sobrevive.Q <- count(pasajero.Q, 
                     "Survived")$freq[2]/nrow(pasajero.Q)*100
sobrevive.S <- count(pasajero.S, 
                     "Survived")$freq[2]/nrow(pasajero.S)*100

sobrevive.1ra <- count(pasajeros.1ra, 
                     "Survived")$freq[2]/nrow(pasajeros.1ra)*100
sobrevive.2da <- count(pasajeros.2da, 
                     "Survived")$freq[2]/nrow(pasajeros.2da)*100
sobrevive.3ra <- count(pasajeros.3ra, 
                     "Survived")$freq[2]/nrow(pasajeros.3ra)*100

```

```{r}
# mostrar los resultados en un dataframe

grupo <- c('mujer', 'hombre', 
           'Cherbourg', 'Queenstown', 'Southampton', 
           '1ra', '2da', '3ra')
proporciones <- c(sobrevive.mujer, sobrevive.hombre, 
                  sobrevive.C, sobrevive.Q, sobrevive.S, 
                  sobrevive.1ra, sobrevive.2da, sobrevive.3ra)
prop_sv <- data.frame(grupo, proporciones)
prop_sv
```


### Modelos de prediccion
En este apartado construiremos diferentes modelos para ver la precision de cadauno de ellos. Utilizaremos el modelo KNN, regresion logistica, Support Vector Machines y CART. Para evealuar las precisiones de las diferentes algoritmos, usaremos la validacion cruzada y la funcion train del paquete caret.
```{r}
library(caret)
# establecer el controlador de entrenamiento trControl
# methodo cross validation de 5 fold
trControl <- trainControl(method = 'cv', number = 5)

# kNN
set.seed(111)
fit.knn <- train(Survived~., data=train_df, 
                 method='knn', metric='Accuracy', trControl=trControl)

# regresion logistica
set.seed(222)
fit.glm <- train(Survived~., data=train_df, 
                 method='glm', metric='Accuracy', trControl=trControl)

# SVM
set.seed(333)
fit.svm <- train(Survived~., data=train_df, method='svmRadial', 
                 metric='Accuracy', trControl=trControl)

# CART
set.seed(444)
fit.cart <- train(Survived~., data=train_df, 
                 method='rpart', metric='Accuracy', trControl=trControl)

```

Una vez tenemos los diferentes modelos, compararemos con la funcion resamples.

```{r}
# comparar modelos
resultado <- resamples(list(KNN=fit.knn, LG=fit.glm, 
                            SVM=fit.svm, CART=fit.cart))
summary(resultado)
dotplot(resultado)
```

Podemos ver que el algoritmo de SVM es el tiene la mejor precision, con un maximo de 85,39%. El segundo es el algoritmo CART donde solo tiene 0.48 menos, con una precision del 84.91%. Por lotanto, utilizaremos el algoritmo SVM.

Una vez tenemos decidido el algoritmo a utilizar, tunearemos para encontrar los parametros optimos. Utilizaremos la funcion tune.svm()
```{r}
library(e1071)
tuned <- tune.svm(Survived~., data=train_df, 
                  gamma=10^(-6:-1), cost = 10^(0:2))
summary(tuned)
```

Vemos que se obtiene mejor resultado con gamma = 0.1 y cost=1.

### Construccion del modelo y prediccion
```{r}
# usaremos el algoritmo con mejor precision: SVM
set.seed(333)
modelo <- svm(Survived ~ ., data=train_df, kernel='radial', 
               gamma=0.1, cost=1)
prediccion <- predict(modelo, test_df)

```

Una vez tenemos la prediccion, añadiremos al subconjunto test_df y compararemos las proporciones con las del subconjunto train_df
```{r}
# Añadir la prediccion al subconjunto de datos test_df
test_df$SurvivedPred <- prediccion

# Agrupar los pasajeros segun el sexo, lugar de embarcamiento y clase
# agrupacion por sexo
pasajerosTs.mujer <- test_df[test_df$Sex == 'female',]
pasajerosTs.hombre <- test_df[test_df$Sex == 'male',]

# agrupacion por clase
pasajerosTs.1ra <- test_df[test_df$Pclass == 1,]
pasajerosTs.2da <- test_df[test_df$Pclass == 2,]
pasajerosTs.3ra <- test_df[test_df$Pclass == 3,]

# agrupacion por lugar de embarcamiento  
pasajeroTs.C <- test_df[test_df$Embarked == 'C',]
pasajeroTs.Q <- test_df[test_df$Embarked == 'Q',]
pasajeroTs.S <- test_df[test_df$Embarked == 'S',]

# calcular numericamente las proporciones
Psobrevive.mujer <- count(pasajerosTs.mujer,
                      "SurvivedPred")$freq[2]/nrow(pasajerosTs.mujer)*100
Psobrevive.hombre <- count(pasajerosTs.hombre, 
                      "SurvivedPred")$freq[2]/nrow(pasajerosTs.hombre)*100

Psobrevive.C <- count(pasajeroTs.C, 
                     "SurvivedPred")$freq[2]/nrow(pasajeroTs.C)*100
Psobrevive.Q <- count(pasajeroTs.Q, 
                     "SurvivedPred")$freq[2]/nrow(pasajeroTs.Q)*100
Psobrevive.S <- count(pasajeroTs.S, 
                     "SurvivedPred")$freq[2]/nrow(pasajeroTs.S)*100

Psobrevive.1ra <- count(pasajerosTs.1ra, 
                     "SurvivedPred")$freq[2]/nrow(pasajerosTs.1ra)*100
Psobrevive.2da <- count(pasajerosTs.2da, 
                     "SurvivedPred")$freq[2]/nrow(pasajerosTs.2da)*100
Psobrevive.3ra <- count(pasajerosTs.3ra, 
                     "SurvivedPred")$freq[2]/nrow(pasajerosTs.3ra)*100

# Añadir los resultados al dataframe de proporciones para comparar
proporcionesPrd <- c(Psobrevive.mujer, Psobrevive.hombre, 
                    Psobrevive.C, Psobrevive.Q, Psobrevive.S, 
                    Psobrevive.1ra, Psobrevive.2da, Psobrevive.3ra)
prop_sv$prop_predic = proporcionesPrd

prop_sv
```

```{r}
# Distribucion de supervivencia en el subconjunto de entremaniento
table(train_df$Survived)
# Distribucion de la prediccion en el subconjunto de test
table(test_df$SurvivedPred)
```

```{r}
# porporcion por sexo de pasajeros embarcado en Queenstown
# subconjunto de test
count(pasajeroTs.Q, 'Sex')
# subconjunto de entrenamiento
count(pasajero.Q, 'Sex')
```

### Conclusión

* En el subconjunto de entremaniento ha sobrevivido 342 pasajeros de los 891, un 38.38%. Mientras en la predicción es de un 38.99%, muy similar al de los casos reales.  
* En la tabla anterior de proporciones de supervivencia por diferentes grupos, vemos que en ambos casos(realidad y prediccion), sobrevive mas mujeres que hombres. Sin embargo, la porporcion de la realidad es de 74.2% y 18.9% respectativamente y la proporcion de la prediccion es de 93.4% y 7.8%. Posiblemente es debido a que nuestro modelo ha dado mas importancia la variable sexo a la hora de predecir.  
* En cuanto a la proporcion por lugar de embarcamiento, el que ha sobrevivido mas es de Cherbourg (55.62%) y nuestro modelo de sobrevivencia es de 50%, un valor similar. Mientras los valores de Queenstown ha pasado de ser 38.9% al 52.2%. Podemos ver en las dos tablas anteriores sobre el sexo de los pasajeros embarcados en queenstown que en el subconjunto de test hay mas mujeres que hombres mientras en el subconjunto de entrenamiento hay mas hombres que mujeres.  
* La distribución de porporciones por clase de pasajeros es similar en ambos casos. Los pasajeros de primera clase hay mas posibilidad de sobrevivir, mientras los de tercera clase solo ha sobrevivido un 24% en subconjunto de entrenamiento y 32% en prediccion.  
* El subconjunto de test al no tener la variable Survived con información real, no hemos podido comprobar directamente nuestra predicción. Pero, mediante analisis de las proporciones podemos concluir que nustro modelo predice correctamente la variable de salida Survived.